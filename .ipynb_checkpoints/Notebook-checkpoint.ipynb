{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21a3223",
   "metadata": {},
   "source": [
    "# Red Wine Quality Prediction Project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3a6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc22ef0",
   "metadata": {},
   "source": [
    "Importing all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245e0240",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwinequality-red.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\mini\\lib\\site-packages\\pandas\\io\\parsers.py:688\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    635\u001b[0m     engine_specified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    637\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    638\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[0;32m    639\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    685\u001b[0m     skip_blank_lines\u001b[38;5;241m=\u001b[39mskip_blank_lines,\n\u001b[0;32m    686\u001b[0m )\n\u001b[1;32m--> 688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\mini\\lib\\site-packages\\pandas\\io\\parsers.py:454\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    451\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\mini\\lib\\site-packages\\pandas\\io\\parsers.py:948\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\mini\\lib\\site-packages\\pandas\\io\\parsers.py:1180\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_engine\u001b[39m(\u001b[38;5;28mself\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[43mCParserWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\New folder\\envs\\mini\\lib\\site-packages\\pandas\\io\\parsers.py:2010\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols_dtype \u001b[38;5;241m=\u001b[39m _validate_usecols_arg(kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   2008\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m-> 2010\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m   2013\u001b[0m passed_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:382\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da49240",
   "metadata": {},
   "source": [
    "Instead of downloading the entire dataset on my local computer I am simply loading the file directly from the GitHub repository link using the raw option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede48a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Taking a look at the dataset's first and last 5 rows showcasing all the column names as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b35764",
   "metadata": {},
   "source": [
    "So by taking a look at the above data frame I can see that the column quality is the target label making the remaining columns as the features that we can customize and use to predict our label. This classifies to be a Classification problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd246111",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54abc2",
   "metadata": {},
   "source": [
    "I see that there are total 1599 rows and 12 columns present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b183a",
   "metadata": {},
   "source": [
    "Luckily we do not see any missing values in any of the columns of our dataset so we don't have to worry about handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a02043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a2742",
   "metadata": {},
   "source": [
    "Great none of the columns have any object data type values and our label is the only integer value making all the feature columns as float datatype i.e. similar datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36480f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924f872",
   "metadata": {},
   "source": [
    "Using the describe method I can see the count, mean, standard deviation, minimum, maximum and inter quantile values of our dataset.\n",
    "\n",
    "As per my observation:\n",
    "1. There is a big gap between 75% and max values of residual sugar column\n",
    "2. There is a big gap between 75% and max values of free sulfur dioxide\tcolumn\n",
    "3. There is a huge gap between 75% and max value of total sulfur dioxide column\n",
    "\n",
    "All these gaps indicate that there are outliers present in our dataset which might need to be treated so as to get a better model accuracy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514099a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.skew() # acceptable range is +/-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82b3f1",
   "metadata": {},
   "source": [
    "Here we see the skewness information present in our dataset. We will ignore quality since it is our target label in the dataset. Now taking a look at all the feature columns we see that fixed acidity, volatile acidity, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, sulphates and alcohol are all outside the acceptable range of +/-0.5. This skewness indicates outliers being present in our dataset that will need to be treated if required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cae1070",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(x ='quality', data = df)\n",
    "plt.xlabel('Quality of Red Wine')\n",
    "plt.ylabel('Count of Rows in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761088a6",
   "metadata": {},
   "source": [
    "In the countplot representation we see the various categories of red wine quality and it shows that the number of data present for quality score 5 and 6 is way higher than it's counterparts. This indicates an imbalance which will need to be rectified so that our machine learning model do not get biased to a certain value during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=0\n",
    "labels = df['quality']\n",
    "features = df.drop('quality', axis=1)\n",
    "\n",
    "for col in features.items():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(x=labels, y=col[index], data=df, color=\"deeppink\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97197696",
   "metadata": {},
   "source": [
    "With the feature vs label barplot we are able to see the trend corresponding to the impact each has with respect to predicting the quality column (our target variable).\n",
    "\n",
    "Observations regarding feature compared to the label are:\n",
    "01. fixed acidity vs quality - no fixed pattern\n",
    "02. volatile acidity vs quality - there is a decreasing trend\n",
    "03. citric acid vs quality - there is an increasing trend\n",
    "04. residual sugar vs quality - no fixed pattern\n",
    "05. chlorides vs quality - there is a decreasing trend\n",
    "06. free sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing\n",
    "07. total sulfur dioxide vs quality - no fixed pattern as it is increasing then decreasing\n",
    "08. density vs quality - no pattern at all\n",
    "09. pH vs quality - no pattern at all\n",
    "10. sulphates vs quality - there is an increasing trend\n",
    "11. alcohol vs quality - there is an increasing trend\n",
    "\n",
    "So here we can conclude that to get better quality wine citric acid, sulphates and alcohol columns play a major role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df.items():\n",
    "    sns.boxplot(y=col, data=df, ax=ax[index])\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4be6f3d",
   "metadata": {},
   "source": [
    "With the help of the above boxplot we are able to see the whisker details and outliers clearly. I am ignoring the continous outlier sections but the outliers that are single values and far away from the whiskers of the boxplot may need to be treated depending upon further analysis. Right now I am just trying to retain as much of data which is possible in the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe484e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=6, nrows=2, figsize=(15,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "for col, value in df.items():\n",
    "    sns.distplot(value, ax=ax[index], hist=False, color=\"g\", kde_kws={\"shade\": True})\n",
    "    index += 1\n",
    "plt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285e2bf4",
   "metadata": {},
   "source": [
    "The distribution plots show that few of the columns are in normal distribution category showing a proper bell shape curve. However, we do see skewness in most of the feature columns like citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, sulphates and alcohol columns. We are going to ignore the label column since it is a categorical column and will need to fix the imbalance data inside it.\n",
    "\n",
    "With respect to the treatment of skewness and outliers I will perform the removal or treatment after I can see the accuracy dependency of the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ec15e",
   "metadata": {},
   "source": [
    "# Correlation using a Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702e19a",
   "metadata": {},
   "source": [
    "1. Positive correlation - A correlation of +1 indicates a perfect positive correlation, meaning that both variables move in the same direction together.\n",
    "\n",
    "2. Negative correlation - A correlation of –1 indicates a perfect negative correlation, meaning that as one variable goes up, the other goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_triangle = np.tril(df.corr())\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, square=True, fmt='0.3f', \n",
    "            annot_kws={'size':5}, cmap=\"Spectral\", mask=lower_triangle)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ffdbf",
   "metadata": {},
   "source": [
    "I see that the above heatmap shows the correlation matrix data wherein there are positive as well as negative correlations between the target label and other feture columns. A zero correlation indicates that there is no relationship between the variables. Looking at the above representation I see that quality column is positively correlated with alcohol and it is negatively correlated with the volatile acidity. The quality column is least correlated with residual sugar showing a coefficient value of 0.014 that close to 0. Similarly we can bifurcate all the other positively and negatively correlated feature columns with respect to the target label.\n",
    "\n",
    "Also there are some highly positive and negative correlated feature columns that can pose the concern for multicollinearity. If the correlation coefficient, assuming it to be the variable 'r', is exactly +1 or -1, then it is called perfect multicollinearity. But even if this 'r' is close to -1 or +1 then one of the features should be removed from the model if at all possible.\n",
    "\n",
    "Right now I see columns fixed acidity and citirc acid are positively correlated with a value of 0.672 which is close to 1. Similary, columns fixed acidity and density are positively correlated with a value of 0.668 again being close to 1. The other 2 column that's positively correlated are free sulfur dioxide and total sulfur dioxide with a value of 0.668 which is close to the value 1. The only negatively correlated columns that pop up are fixed acitidy and pH with a value -0.683 being close to the value -1.\n",
    "\n",
    "We may need to deal with multicollinearity later if required to improve the accuracy of our machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71cb70",
   "metadata": {},
   "source": [
    "# Dropping a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('free sulfur dioxide', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69194891",
   "metadata": {},
   "source": [
    "I feel that free sulfur dioxide and total sulfur dioxide are both indicating towards the same feature of sulfur dioxide therefore I am dropping the free option and keeping just the total option in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aba379",
   "metadata": {},
   "source": [
    "# Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6492b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b2312",
   "metadata": {},
   "source": [
    "Confirming the number of columns and rows before removing the outliers from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score method\n",
    "\n",
    "z=np.abs(zscore(df))\n",
    "threshold=3\n",
    "np.where(z>3)\n",
    "\n",
    "df=df[(z<3).all(axis=1)]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ab63a",
   "metadata": {},
   "source": [
    "I have used the Z score method to get rid of outliers present in our dataset that are not in the acceptable range of +/-0.5 value of skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3253da9",
   "metadata": {},
   "source": [
    "Checking the number of rows present in the dataset after applying the outlier removal technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Data Loss\n",
    "\n",
    "data_loss=(1599-1464)/1599*100 \n",
    "# 1599 (number of rows in the original dataframe) and 1464 (number of rows after outlier removal)\n",
    "data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b633f4",
   "metadata": {},
   "source": [
    "After removing the outliers we are checking the data loss percentage by comparing the rows in our original data set and the new data set post removal of the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773568d",
   "metadata": {},
   "source": [
    "# Splitting the dataset into 2 variables namely 'X' and 'Y' for feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis=1)\n",
    "Y = df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d9a1b",
   "metadata": {},
   "source": [
    "I have bifurcated the dataset into features and labels where X represents all the feature columns and Y represents the target label column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e358cb4",
   "metadata": {},
   "source": [
    "### Taking care of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2c23e",
   "metadata": {},
   "source": [
    "Listing the values of our label column to count the number of rows occupied by each category. This indicates class imbalance that we will need to fix by using the oversampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding samples to make all the categorical quality values same\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151cb88",
   "metadata": {},
   "source": [
    "SMOTE is the over sampling mechanism that we are using to ensure that all the categories present in our target label have the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e982d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adfbea",
   "metadata": {},
   "source": [
    "After applying over sampling we are one again listing the values of our label column to cross verify the updated information. Here we see that we have successfully resolved the class imbalance problem and now all the categories have same data ensuring that the machine learning model does not get biased towards one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7609098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y # Displaying just the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9cdcad",
   "metadata": {},
   "source": [
    "### Label Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929702d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = Y.apply(lambda y_value:1 if y_value>=7 else 0) # 1 is for good quality and 0 for bad (not good) quality\n",
    "Y # Displaying the label after applying label binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14677a",
   "metadata": {},
   "source": [
    "Using the label binarization technique we have tagged the categories present in our target label to 2 major class that are 0 for bad quality wine and 1 for good quality wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X # Displaying all the features except the label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e2e1b",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X # Displaying all the features after applying scaling technique to avoid bias output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a612f6",
   "metadata": {},
   "source": [
    "Even though all our feature columns were of float data type I was unhappy with the decimal place differences and was worried that it might make my model biased. Therefore I am using the Standard Scaler method to ensure all my feature columns have been standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b627576",
   "metadata": {},
   "source": [
    "# Creating the training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90809739",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ad04c",
   "metadata": {},
   "source": [
    "I am taking 20 percent of the complete dataset for training purpose and the remaing 80 percent with be used to train the machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2c4bb",
   "metadata": {},
   "source": [
    "# Machine Learning Model for Classification and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e456b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model Function\n",
    "\n",
    "def classify(classifier,model, X, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=21)\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predicting Y_test\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy Score\n",
    "    acc_score = (accuracy_score(Y_test, pred))*100\n",
    "    print(\"Accuracy Score:\", acc_score)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(Y_test, pred)\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "    \n",
    "    # Cross Validation Score\n",
    "    cv_score = (cross_val_score(model, X, Y, cv=5).mean())*100\n",
    "    print(\"Cross Validation Score:\", cv_score)\n",
    "    \n",
    "    # Result of accuracy minus cv scores\n",
    "    result = acc_score - cv_score\n",
    "    print(\"\\nAccuracy Score - Cross Validation Score is\", result)\n",
    "    \n",
    "    results.update({classifier:acc_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33add9d",
   "metadata": {},
   "source": [
    "I have defined a class that will perform the train-test split, training of machine learning model, predicting the label value, getting the accuracy score, generating the classification report, getting the cross validation score and the result of difference between the accuracy score and cross validation score for any machine learning model that calls for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede27a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model=LogisticRegression()\n",
    "classify(\"LR\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161c34d",
   "metadata": {},
   "source": [
    "Created the Logistic Regression Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30cfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "model=SVC(C=1.0, kernel='rbf', gamma='auto', random_state=42)\n",
    "classify(\"SVC\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ab2c4",
   "metadata": {},
   "source": [
    "Created the Support Vector Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "model=DecisionTreeClassifier(random_state=21, max_depth=15)\n",
    "classify(\"DT\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87813918",
   "metadata": {},
   "source": [
    "Created the Decision Tree Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e82ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "model=RandomForestClassifier(max_depth=15, random_state=111)\n",
    "classify(\"RF\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc130f9",
   "metadata": {},
   "source": [
    "Created the Random Forest Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba4d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K Neighbors Classifier\n",
    "\n",
    "model=KNeighborsClassifier(n_neighbors=15)\n",
    "classify(\"KNN\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33b0c8",
   "metadata": {},
   "source": [
    "Created the K Neighbors Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2090692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "model=ExtraTreesClassifier()\n",
    "classify(\"ET\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc4d077",
   "metadata": {},
   "source": [
    "Created the Extra Trees Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcdef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB Classifier\n",
    "model=xgb.XGBClassifier(verbosity=0)\n",
    "classify(\"XGB\",model, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7393db",
   "metadata": {},
   "source": [
    "Created the XGB Classifier Model and checked for it's evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting keys and values\n",
    "keys = list(results.keys())\n",
    "values = list(results.values())\n",
    "\n",
    "plt.figure(figsize=(5,5))  # Adjust the width and height as needed\n",
    "# Creating the bar chart\n",
    "plt.bar(keys, values)\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Accuracy Comparision')\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd62e7a-48d8-407d-ac3e-7356f5b55aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(scaler,open(\"scaler.pkl\",\"wb\"))\n",
    "pickle.dump(model,open(\"xgboost_model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57065f7b-a111-4a56-be45-a7f0eb019cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
